{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix_Factorization_ALS {-}\n",
    "#### Team: Ground Truth - Connor DePalma & Daniel Pelis {-} \n",
    "#### EE627 {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sc.textFile(\"./data/trainItem.data\")\n",
    "train_ratings = train_data.map(lambda l: l.split(','))\\\n",
    " .map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sc.textFile(\"./data/trainItem.data\")\n",
    "train_ratings = train_data.map(lambda l: l.split(','))\\\n",
    " .map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 10\n",
    "numIterations = 10\n",
    "model = ALS.train(train_ratings, rank, numIterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data\n",
    "del train_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFile = sc.textFile(\"./data/testItem.data\")\n",
    "test_ratings = testFile.map(lambda l: l.split(','))\\\n",
    " .map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = test_ratings.map(lambda p: (p[0], p[1]))\n",
    "predictions = model.predictAll(testdata).map(lambda r: (r[0], r[1], r[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions.coalesce(1).saveAsTextFile('./data/preds_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rather than creating the dataframe directly, we found more success in saving it as a file first. By doing this we are essentially saving our data in case anything memory related fails, which happened alot on our machines during these tests. If anything fails due to memory or resource constraints after this point, we are able to restart the notebook and are then only required to run in import statements prior to this point, thus saving a lot of resources. {-}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = predictions.coalesce(1).toDF().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = pd.read_csv('./data/preds_2/part-00000', dtype=str, names=['_1', '_2', '_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['_1'] = preds['_1'].str[1:].astype(np.int64)\n",
    "preds['_3'] = preds['_3'].str[:-1].astype(np.float64)\n",
    "preds['_2'] = preds['_2'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.sort_values(['_1'], ascending=True) \\\n",
    "    .groupby(['_1'], sort=False) \\\n",
    "    .apply(lambda x: x.sort_values(['_3'], ascending=False)) \\\n",
    "    .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds.to_csv(\"./data/preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir='./data/'\n",
    "file_name_ratings=dataDir + 'testItem.data'\n",
    "ratings = open(file_name_ratings, 'r')\n",
    "#preds = pd.read_csv(dataDir + 'preds.csv')\n",
    "out_file = dataDir + 'submission_3.csv'\n",
    "\n",
    "with open(out_file,'w') as f:\n",
    "    row = 'TrackID,Predictor\\n'\n",
    "    f.write(row)\n",
    "\n",
    "index = 0\n",
    "while ratings:\n",
    "    if index > 119973:\n",
    "        break\n",
    "    # grab first six rows in df\n",
    "    user_preds_user_id = preds.iloc[index,0]\n",
    "    user_preds = []\n",
    "    for x in range(6):\n",
    "        if(preds.iloc[index,0] == user_preds_user_id):\n",
    "            user_preds.append(preds.iloc[index])\n",
    "            index += 1\n",
    "    # user_preds = preds[index:index+6]\n",
    "    \n",
    "\n",
    "    # Load user rows into their own data frame with extra col intialized at 0\n",
    "    user_df = pd.DataFrame(data=user_preds)\n",
    "    user_df['_4'] = 0\n",
    "    \n",
    "    # Sort user df by rank and assign top three with ones\n",
    "    i = 0\n",
    "    for i in range(len(user_df['_1'])):\n",
    "        if i < 3:\n",
    "            user_df.iloc[i,3] = 1\n",
    "\n",
    "    user_id = int(user_df.iloc[0,0])\n",
    "\n",
    "    lines = []\n",
    "    while len(lines) < 6:\n",
    "        line = ratings.readline()\n",
    "        data = line.strip().split(',')\n",
    "        if str(user_id) == str(data[0]):\n",
    "            lines.append(data)\n",
    "\n",
    "    with open(out_file,'a') as f:\n",
    "        for line in lines:\n",
    "            userId = line[0]\n",
    "            item_id = line[1]\n",
    "            df_row = user_df.loc[user_df['_2'] == int(item_id)]\n",
    "            try:\n",
    "                value = df_row['_4'].values[0]\n",
    "                row = f'{userId}_{item_id},{value}\\n'\n",
    "            except:\n",
    "                row = f'{userId}_{item_id},0\\n'\n",
    "            f.write(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
